**University** : [ITMO University](https://itmo.ru/ru/)

**Faculty** : [FICT](https://fict.itmo.ru)

**Course** : [Cloud platforms as the basis of technology entrepreneurship](https://itmo-ict-faculty.github.io/cloud-platforms-as-the-basis-of-technology-entrepreneurship/)

**Year**: 2024/2025

**Group** : U4225

**Author** : Semykina Vera Stanislavovna

**Lab**: Lab2

**Date of create**: 25.10.2024

**Date of finished** : 25.10.2024

# Лабораторная работа №2: "Исследование Cloud Run"

## Цель работы:
Познакомиться с основами сервиса **Google Cloud Run**, протестировать его основные возможности, научиться работать с логами и метриками, а также провести эксперименты с изменением порта и переключением трафика между версиями.

## Ход работы:

## 1. Создание сервиса Cloud Run на основе шаблона Hello
Использовала **Google Cloud Console** для создания нового сервиса Cloud Run на основе дефолтного образа Hello. Был выбран общедоступный доступ для тестирования без авторизации. После успешного деплоя Cloud Run предоставил **URL-адрес**, по которому можно перейти и протестировать работу сервиса.
![image](https://github.com/user-attachments/assets/67e2041e-5fa7-41e1-9501-c11516f2bb15)

## 2. Тестирование работы сервиса
- Открыла предоставленный URL в браузере;
- При запуске сервиса увидела дефолтное приветственное сообщение "Hello, World!";
- Убедились, что Cloud Run работает корректно с минимальными ресурсами.

![image](https://github.com/user-attachments/assets/1a2c2869-3308-4876-ad76-e506c93bb73a)

## 3. Анализ логов и метрик

### Просмотр логов
Перешла в раздел **Logs** через интерфейс Cloud Run. Проанализировала логи, которые включали информацию о каждом запросе, времени отклика и состоянии выполнения.
Логи не содержали ошибок, что подтверждает корректную работу сервиса.
![image](https://github.com/user-attachments/assets/80c969cd-5789-45d5-b023-d99c741b5045)

![image](https://github.com/user-attachments/assets/9e4f701a-d184-431a-a548-da43ea993cc2)


### Анализ метрик
Перешла в раздел **Metrics** в консоли Cloud Run.
![image](https://github.com/user-attachments/assets/d2b1a86c-aed5-4676-9bc5-1f6aeea7d033)

![image](https://github.com/user-attachments/assets/c00b63ca-5d12-408c-af37-513322afd4ec)

![image](https://github.com/user-attachments/assets/342bac79-6a25-496c-9dd5-5cc21c02fbb0)

- **Request Count (Количество запросов)** - график показывает стабильное количество запросов с небольшим пиковым значением около 2:14 PM. Это указывает на периодические обращения к сервису, но в целом количество запросов остается низким, что соответствует нашему тестовому использованию.
- **Request latencies ( Задержка запросов)** — низкие значения, что говорит о быстрой обработке запросов, около 10-15 мс.
- **Container Instance Count (Количество контейнерных экземпляров)** - появляется один активный экземпляр контейнера, который выполняет запросы, минимульная загрузка сервиса
- **CPU Utilization** и **Memory Utilization** — использование CPU остается на уровне до 4%, что достаточно низко, а память постепенно возрастает до 5%. Это подтверждает, что ресурсные потребности приложения минимальны и сервис работает без перегрузок.
- **Max Concurrent Requests (Максимальное количество одновременных запросов)** - максимально одновременно обрабатывается 1-2 запроса
- **Container Startup Latency (Время запуска контейнера)** - время запуска контейнера составляет около 80 мс, быстроый доступн к сервису.

## 4. Изменение порта сервиса

Изменила конфигурацию Cloud Run, установив порт **8090**, поменяв с 8080.
Перезапустила сервис с новой версией.
![image](https://github.com/user-attachments/assets/5cff506b-faf6-4939-be28-9668c04b6673)

Сервис успешно заработал на новом порте. Важно отметить, что в Cloud Run автоматически осуществляется маршрутизация, поэтому URL остался прежним, а изменения коснулись только внутренней настройки.
Проверила работу сервиса после изменения порта, чтобы убедиться в корректной обработке запросов.
 ![image](https://github.com/user-attachments/assets/6d41fd27-f559-4f27-bda7-8357ae0161db)

### Просмотр логов
![image](https://github.com/user-attachments/assets/769d4f26-e6cb-41f1-8999-4815e388e423)

![image](https://github.com/user-attachments/assets/aac7e4e8-5b6d-456b-9def-b84c52b6a25a)

### Анализ метрик

![image](https://github.com/user-attachments/assets/09ba806c-ec6c-4f78-8aa8-4f27bc1247c0)


![image](https://github.com/user-attachments/assets/9bda7179-b4e5-4ac9-97f8-9c975ce55a84)


![image](https://github.com/user-attachments/assets/f81adda5-a741-4e8f-a6cd-8ea3cd1b3f74)

- **Request Count (Количество запросов)** - более низкон и редкое кол-во запросов по сравнению с портом 8080
- **Request latencies ( Задержка запросов)** — аналогично 8080, низкие значения, что говорит о быстрой обработке запросов, около 10-15 мс.
- **Container Instance Count (Количество контейнерных экземпляров)** - аналогично 8080, появляется один активный экземпляр контейнера, который выполняет запросы, минимульная загрузка сервиса
- **CPU Utilization** и **Memory Utilization** — аналогично 8080
- **Max Concurrent Requests (Максимальное количество одновременных запросов)** - максимально одновременно обрабатывается 1-2 запроса
- **Container Startup Latency (Время запуска контейнера)** - время запуска контейнера составляет около 70-74 мс, аналогично 8080


## 5. Переключение трафика между версиями

В разделе **Revisions** распределила трафик между старой и новой версиями. Выполнила тестовые запросы для проверки распределения трафика между версиями. В логах отразилась работа обеих версий, что подтвердило корректное распределение трафика. При переходе по URL несколько раз были замечены отличия в ответах, что указывало на то, что запросы обрабатываются обоими версиями.
##### Оба сервиса на порте 8080

![image](https://github.com/user-attachments/assets/04b2a4d5-1b01-48a2-bd1d-48dd0c602742)

![image](https://github.com/user-attachments/assets/9ee374f0-e2be-4297-8c60-2dafb2e13732)

  * ### 50\50. Просмотр метрик
![image](https://github.com/user-attachments/assets/1fc06f86-7ad8-4e81-a271-94cfc603052b)

![image](https://github.com/user-attachments/assets/4bb8b243-1732-43ba-83ac-5c03f8ca2542)

![image](https://github.com/user-attachments/assets/88b4c060-ab9d-476d-850e-741471743f2d)

![image](https://github.com/user-attachments/assets/e777acb6-983d-41bc-9fd0-2c6da186a224)

#### Распределение трафика:
![image](https://github.com/user-attachments/assets/5ca9b2d4-c81b-4f35-af2d-a65aab405cf5)

  * ### 90\10
    
#### Распределение трафика:
![image](https://github.com/user-attachments/assets/a8191c08-8c44-46e1-b59e-54db0a65f0b6)

### Просмотр метрик
![image](https://github.com/user-attachments/assets/45d9f79c-87a9-4929-adfd-01e3b80a8e4c)

![image](https://github.com/user-attachments/assets/82716751-b673-4930-bfd3-a8c33e1718fb)

![image](https://github.com/user-attachments/assets/4f587031-1528-4635-a62c-09c73da0aba6)

**Количество запросов (Request Count)**
Наблюдается пик количества запросов, что может быть связано с увеличением трафика после добавления новой версии. Большая часть трафика направлена на основную версию (90%), что видно из общего распределения запросов.

**Задержка запросов (Request Latency)**
Средняя задержка остается на уровне около 50 -100 мс, стабильная работа сервиса. 

**Количество контейнерных экземпляров (Container Instance Count)**
Появились два активных контейнера.

**Использование процессора и памяти контейнера (Container CPU and Memory Utilization)**
Показатели загрузки CPU остаются на низком уровне

**Максимальное количество одновременных запросов (Max Concurrent Requests)**
Видно, что количество одновременных запросов увеличилось до 2, видно распределение нагрузки.

**Переданные и полученные байты (Sent Bytes и Received Bytes)**
Количество переданных и полученных данных возросло во время пиковых значений, что указывает на обработку запросов обеими версиями. Новая версия начала получать небольшую часть трафика, и это распределение отразилось в данных по сетевой активности.

**Время запуска контейнера (Container Startup Latency)**
время запуска не больше 100 мс, стабильная работа сервиса
**Заключение:**
Добавление новой версии на порт 8080 с распределением трафика 90% и 10% прошло успешно, и сервис продолжает работать стабильно. Основные метрики показывают, что распределение трафика не вызвало перегрузок, а система справляется с обработкой запросов.


### Играюсь с трафиком на разных портах (8080 и 8090)
* ## 60/40
![image](https://github.com/user-attachments/assets/f495bd8e-3680-4ad7-98f7-623ebb1c0bcc)

#### Распределение трафика:
![image](https://github.com/user-attachments/assets/56b4d1e1-00d5-41ce-ad3f-982ebf942f4c)
#### Метрики:
![image](https://github.com/user-attachments/assets/5231a77c-9ca9-49c1-be70-753b9191b481)
![image](https://github.com/user-attachments/assets/df385059-ca45-49a6-8a23-2f694e984793)
![image](https://github.com/user-attachments/assets/c8fff7aa-f1a1-401d-a332-daa3ec7f526a)

* ## 90/10

![image](https://github.com/user-attachments/assets/b76c72b9-60a5-41db-adf7-118b2b4d9b3c)

#### Распределение трафика:
![image](https://github.com/user-attachments/assets/52d6f865-0de1-49ff-a174-10dbb08e66c8)

#### Метрики:
![image](https://github.com/user-attachments/assets/b0e951d9-1bf4-4ecc-b3ae-c32b6f930448)
![image](https://github.com/user-attachments/assets/00798d3f-5767-4782-9c4d-192d2d7226ac)
![image](https://github.com/user-attachments/assets/599c3c4a-646a-4643-ad54-47077677f5a1)

**Количество запросов (Request Count)**
График показывает пик активности, связанный с увеличением числа запросов после разделения трафика. Несмотря на доминирование трафика на старую версию, новая версия также получает некоторую часть запросов, что подтверждает корректное распределение.

**Задержка запросов (Request Latency)**
Средняя задержка остается на уровне около 10 мс для обеих версий, что говорит о стабильной производительности даже при распределении трафика. Разделение не повлияло на скорость отклика сервиса, что указывает на успешное масштабирование.

**Количество контейнерных экземпляров (Container Instance Count)**
Появились два активных контейнера, что связано с запуском новой версии на порту 8090. Важно отметить, что оба экземпляра работают параллельно, что обеспечивает отказоустойчивость и распределение нагрузки.

**Использование процессора и памяти контейнера (Container CPU and Memory Utilization)**
Показатели загрузки CPU остаются на низком уровне

**Максимальное количество одновременных запросов (Max Concurrent Requests)**
Видны небольшие колебания. Одновременные запросы остаются на уровне 1-2, что говорит о сбалансированной нагрузке между версиями.

**Переданные и полученные байты (Sent Bytes и Received Bytes)**
Количество переданных и полученных данных возросло во время пиковых значений, что указывает на обработку запросов обеими версиями. Новая версия начала получать небольшую часть трафика, и это распределение отразилось в данных по сетевой активности.

**Время запуска контейнера (Container Startup Latency)**
На графике не отображается новая задержка запуска, что может означать отсутствие значительных задержек или корректное использование кеширования при запуске нового контейнера.

**Заключение:**
Добавление новой версии на порт 8090 и распределение трафика 90/10 прошло успешно, при этом общая производительность сервиса осталась стабильной.

## Выводы:
Создание разных версий контейнера позволяет распределять трафик и создавать правила его распределения, что является ключевым аспектом для того, чтобы контролировать развертывание приложений, проводить A/B тестирование, вводить новые функции постепенно и управлять версиями приложений.

### Результаты лабораторной работы
- В ходе выполнения работы был успешно развернут сервис на Cloud Run.
- Проведено тестирование работы сервиса, настройка минимального уровня ресурсов.
- Проанализированы логи и метрики, что дало представление о производительности и нагрузке на сервис.
- Проверено поведение сервиса при изменении порта — было установлено, что Cloud Run поддерживает работу с портом 8080 по умолчанию.
- Проведен эксперимент с переключением трафика между версиями, что продемонстрировало гибкость Cloud Run в управлении трафиком и версиями.

Cloud Run предоставляет мощные возможности для развертывания контейнеризированных приложений с минимальными усилиями и высокой гибкостью в управлении версиями и трафиком. Сервис автоматически масштабируется под нагрузку, при этом сохраняется простота настройки и управления.






